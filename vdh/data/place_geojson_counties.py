#write a script to nest counties in a given GeoJSON file inside a US level GeoJSON file
#usage: python3 place_geojson_counties.py <US level GeoJSON file> <State Abbreviation> <US counties file>
#example: python3 place_geojson_counties.py  --us us-states.geo.json --state va --counties georef-united-states-of-america-county.geojson

import json
import sys
import argparse
DC_STATEHOOD=1
import us as us_package
from copy import deepcopy
import os


#open the US level GeoJSON file
#use argparse to get the files
parser = argparse.ArgumentParser(description='Merge two GeoJSON files.')
parser.add_argument('--us', metavar='us', type=str, help='US level GeoJSON file')
parser.add_argument('--state', metavar='state', type=str, help='State of interest')
#Argument for "georef-united-states-of-america-county.geojson" file
parser.add_argument('--counties', metavar='counties', type=str, help='File containing all US counties')
#**LINE BELOW NO LONGER WORKS. Instead, it is done automattically with --state flag
# parser.add_argument('--remove', metavar='remove', type=str, help='name of state to remove features from US level GeoJSON file', default=None)

args = parser.parse_args()

web_directory = "../www/recalculateData"
if not os.path.exists(web_directory):
    os.makedirs(web_directory)

#Find state of interest from command line argument
all_counties_geojson = args.counties
interest_state_abbr = args.state[:2]
interest_state = str(us_package.states.lookup(interest_state_abbr))

#Get the geojson of first CLI argument and stored geojson file
with open(args.us) as f, open(all_counties_geojson) as f2:
    us_map = json.load(f)
    all_counties = json.load(f2)
    

#deep copy the us_map
us_orig = deepcopy(us_map)

#Remove the state from the US if specified AND decrement following IDs to fill in gap
if args.state != None:
    id_offset = 0
    i = 0
    while i < len(us_map['features']):
        feature = us_map['features'][i]
        if feature['properties']['name'] == interest_state:
            del us_map['features'][i]  #remove the feature with the interest_state
            id_offset = -1  #set the offset to -1 once the state is removed
        else:
            feature['id'] += id_offset  
            i += 1 

      
#find relevant counties using interest_state and all_counties_geojson
counties = []
for feature in all_counties['features']:
    if feature['properties']['ste_name'][0] == interest_state:
        feature["properties"]["name"] = feature["properties"]["coty_name_long"][0]
        counties.append(feature)

#get the id of the last US feature
us_id = int(us_map['features'][-1]['id'])
#append each of the state features to the US features
for feature in counties:
    us_id += 1
    feature['id'] = us_id
    #append :{state abbreviation} to the end of the name
    feature['properties']['coty_name_long'] = feature['properties']['coty_name_long'][0]
    feature['properties']['coty_code'] = feature['properties']['coty_code'][0]

    us_map['features'].append(feature)

#write the new GeoJSON file
#create mashup file name between US and state
#concetenates '_counties.geojson' to state abbreviation to preserve GeoJSON format
mashup = args.us.split('.')[0] + '_' + str(interest_state_abbr) + '-counties.geo.json'
# mashup = os.path.join(web_directory, f'{os.path.splitext(args.us)[0]}_{str(interest_state_abbr)}-counties.geo.json')
with open(mashup, 'w') as outfile:
    json.dump(us_map, outfile)

#write a state_and_county_lexicon.{state abbreviation}.txt file in similar style to https://github.com/aswarren/clustertracker_va/blob/vdhct/vdh/data/state_and_county_lexicon.va.txt
#Using the GeoJSON file, generates the following three column format: 1) Long County Name + State Abbreviation 2) FIPS Code 3) County name
#open the file

county_lexicon_path = os.path.join(web_directory, f'county_lexicon.{interest_state_abbr}.txt')

# with open(f'state_and_county_lexicon.{interest_state_abbr}.txt', 'w') as f, open(f'county_lexicon.{interest_state_abbr}.txt', 'w') as f2:
with open(f'state_and_county_lexicon.{interest_state_abbr}.txt', 'w') as f, open(county_lexicon_path, 'w') as f2:
    for feature in counties:
        f.write(','.join([feature['properties']['coty_name_long'],feature['properties']['coty_code'],feature['properties']['name']]) + '\n')
        f2.write(','.join([feature['properties']['coty_name_long'],feature['properties']['coty_code'],feature['properties']['name']]) + '\n')

    #now write all the states in the US and their abbreviation, use python library to get the abbreviation
    for feature in us_orig['features']:
        #print(feature['properties']['name'])
        if feature['properties']['name'] == 'District of Columbia':
            f.write(feature['properties']['name'] + ',' + 'DC' + '\n')
        else:
            if us_package.states.lookup(feature['properties']['name']) == None:
                print('Could not find the following in US states package: ' + feature['properties']['name'])
            elif us_package.states.lookup(feature['properties']['name']).abbr != None:
                f.write(feature['properties']['name'] + ',' + us_package.states.lookup(feature['properties']['name']).abbr + '\n')